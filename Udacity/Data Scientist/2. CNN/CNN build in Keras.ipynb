{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To create a convolutional layer in Keras, you must first import the necessary module:\n",
    "from keras.layers import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then, you can create a convolutional layer by using the following format:\n",
    "Conv2D(filters, kernel_size, strides, padding, activation='relu', input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Argument\n",
    "You must pass the following arguments:\n",
    "\n",
    "filters - The number of filters.\n",
    "kernel_size - Number specifying both the height and width of the (square) convolution window.\n",
    "There are some additional, optional arguments that you might like to tune:\n",
    "\n",
    "strides - The stride of the convolution. If you don't specify anything, strides is set to 1.\n",
    "padding - One of 'valid' or 'same'. If you don't specify anything, padding is set to 'valid'.\n",
    "activation - Typically 'relu'. If you don't specify anything, no activation is applied. You are strongly encouraged to add a ReLU activation function to every convolutional layer in your networks.\n",
    "\n",
    "NOTE: It is possible to represent both kernel_size and strides as either a number or a tuple.\n",
    "\n",
    "When using your convolutional layer as the first layer (appearing after the input layer) in a model, you must provide an additional input_shape argument:\n",
    "\n",
    "input_shape - Tuple specifying the height, width, and depth (in that order) of the input.\n",
    "NOTE: Do not include the input_shape argument if the convolutional layer is not the first layer in your network.\n",
    "\n",
    "There are many other tunable arguments that you can set to change the behavior of your convolutional layers. To read more about these, we recommend perusing the official documentation.\n",
    "\n",
    "Example 1\n",
    "Say I'm constructing a CNN, and my input layer accepts grayscale images that are 200 by 200 pixels (corresponding to a 3D array with height 200, width 200, and depth 1). Then, say I'd like the next layer to be a convolutional layer with 16 filters, each with a width and height of 2. When performing the convolution, I'd like the filter to jump two pixels at a time. I also don't want the filter to extend outside of the image boundaries; in other words, I don't want to pad the image with zeros. Then, to construct this convolutional layer, I would use the following line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv2D(filters=16, kernel_size=2, strides=2, activation='relu', input_shape=(200, 200, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 2\n",
    "Say I'd like the next layer in my CNN to be a convolutional layer that takes the layer constructed in Example 1 as input. Say I'd like my new layer to have 32 filters, each with a height and width of 3. When performing the convolution, I'd like the filter to jump 1 pixel at a time. I want the convolutional layer to see all regions of the previous layer, and so I don't mind if the filter hangs over the edge of the previous layer when it's performing the convolution. Then, to construct this convolutional layer, I would use the following line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv2D(filters=32, kernel_size=3, padding='same', activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 3\n",
    "If you look up code online, it is also common to see convolutional layers in Keras in this format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv2D(64, (2,2), activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, there are 64 filters, each with a size of 2x2, and the layer has a ReLU activation function. The other arguments in the layer use the default values, so the convolution uses a stride of 1, and the padding has been set to 'valid'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dimensionality\n",
    "Create a CNN in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 50, 50, 10)        50        \n",
      "=================================================================\n",
      "Total params: 50\n",
      "Trainable params: 50\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=10, kernel_size=2, strides=4, padding='valid', \n",
    "    activation='relu', input_shape=(200, 200, 1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take note of how the number of parameters in the convolutional layer changes. This corresponds to the value under Param # in the printed output. In the figure above, the convolutional layer has 80 parameters.\n",
    "\n",
    "Also notice how the shape of the convolutional layer changes. This corresponds to the value under Output Shape in the printed output. In the figure above, None corresponds to the batch size, and the convolutional layer has a height of 100, width of 100, and depth of 16.\n",
    "\n",
    "Formula: Number of Parameters in a Convolutional Layer\n",
    "The number of parameters in a convolutional layer depends on the supplied values of filters, kernel_size, and input_shape. Let's define a few variables:\n",
    "\n",
    "K - the number of filters in the convolutional layer\n",
    "F - the height and width of the convolutional filters\n",
    "D_in - the depth of the previous layer\n",
    "Notice that K = filters, and F = kernel_size. Likewise, D_in is the last value in the input_shape tuple.\n",
    "\n",
    "Since there are （F * F * D_in） weights per filter, and the convolutional layer is composed of K filters, the total number of weights in the convolutional layer is （K* F * F * D_in）. Since there is one bias term per filter, the convolutional layer has K biases. Thus, the number of parameters in the convolutional layer is given by（K* F * F * D_in） + K.\n",
    "\n",
    "Formula: Shape of a Convolutional Layer\n",
    "The shape of a convolutional layer depends on the supplied values of kernel_size, input_shape, padding, and stride. Let's define a few variables:\n",
    "\n",
    "K - the number of filters in the convolutional layer\n",
    "F - the height and width of the convolutional filters\n",
    "S - the stride of the convolution\n",
    "H_in - the height of the previous layer\n",
    "W_in - the width of the previous layer\n",
    "Notice that K = filters, F = kernel_size, and S = stride. Likewise, H_in and W_in are the first and second value of the input_shape tuple, respectively.\n",
    "\n",
    "The depth of the convolutional layer will always equal the number of filters K.\n",
    "\n",
    "If padding = 'same', then the spatial dimensions of the convolutional layer are the following:\n",
    "\n",
    "height = ceil(float(H_in) / float(S))\n",
    "width = ceil(float(W_in) / float(S))\n",
    "\n",
    "If padding = 'valid', then the spatial dimensions of the convolutional layer are the following:\n",
    "\n",
    "height = ceil(float(H_in - F + 1) / float(S))\n",
    "width = ceil(float(W_in - F + 1) / float(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=3, strides=2, padding='same', \n",
    "    activation='relu', input_shape=(128, 128, 3)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max Pooling Layers in Keras\n",
    "To create a max pooling layer in Keras, you must first import the necessary module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you can create a convolutional layer by using the following format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaxPooling2D(pool_size, strides, padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguments\n",
    "You must include the following argument:\n",
    "\n",
    "pool_size - Number specifying the height and width of the pooling window.\n",
    "There are some additional, optional arguments that you might like to tune:\n",
    "\n",
    "strides - The vertical and horizontal stride. If you don't specify anything, strides will default to pool_size.\n",
    "padding - One of 'valid' or 'same'. If you don't specify anything, padding is set to 'valid'.\n",
    "NOTE: It is possible to represent both pool_size and strides as either a number or a tuple.\n",
    "\n",
    "You are also encouraged to read the official documentation.\n",
    "\n",
    "Example\n",
    "Say I'm constructing a CNN, and I'd like to reduce the dimensionality of a convolutional layer by following it with a max pooling layer. Say the convolutional layer has size (100, 100, 15), and I'd like the max pooling layer to have size (50, 50, 15). I can do this by using a 2x2 window in my max pooling layer, with a stride of 2, which could be constructed in the following line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " MaxPooling2D(pool_size=2, strides=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd instead like to use a stride of 1, but still keep the size of the window at 2x2, then you'd use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " MaxPooling2D(pool_size=2, strides=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the Dimensionality of Max Pooling Layers\n",
    "Copy and paste the following code into a Python executable named pool-dims.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2, input_shape=(100, 100, 15)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN for classification\n",
    "from keras.models import Sequential\n",
    "#We import several layers, including layers that are familiar from neural networks, and new layers that we learned about in this lesson.\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network begins with a sequence of three convolutional layers, followed by max pooling layers. These first six layers are designed to take the input array of image pixels and convert it to an array where all of the spatial information has been squeezed out, and only information encoding the content of the image remains. The array is then flattened to a vector in the seventh layer of the CNN. It is followed by two dense layers designed to further elucidate the content of the image. The final layer has one entry for each object class in the dataset, and has a softmax activation function, so that it returns probabilities.\n",
    "\n",
    "NOTE: In the video, you might notice that convolutional layers are specified with Convolution2D instead of Conv2D. Either is fine for Keras 2.0, but Conv2D is preferred.\n",
    "\n",
    "Things to Remember\n",
    "Always add a ReLU activation function to the Conv2D layers in your CNN. With the exception of the final layer in the network, Dense layers should also have a ReLU activation function.\n",
    "When constructing a network for classification, the final layer in the network should be a Dense layer with a softmax activation function. The number of nodes in the final layer should equal the total number of classes in the dataset.\n",
    "Have fun! If you start to feel discouraged, we recommend that you check out Andrej Karpathy's tumblr with user-submitted loss functions, corresponding to models that gave their owners some trouble. Recall that the loss is supposed to decrease during training. These plots show very different behavior :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
